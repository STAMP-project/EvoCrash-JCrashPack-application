[2017-10-03T11:24:39,246][WARN ][o.e.r.RepositoriesService] [master-HOSTNAME] failed to create repository [hdfs][REPOSITORY]
java.security.AccessControlException: access denied ("java.security.SecurityPermission" "putProviderProperty.SaslPlainServer")
	at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472) ~[?:1.8.0_121]
	at java.security.AccessControlContext.checkPermission2(AccessControlContext.java:538) ~[?:1.8.0_121]
	at java.security.AccessControlContext.checkPermission(AccessControlContext.java:481) ~[?:1.8.0_121]
	at java.security.AccessController.checkPermission(AccessController.java:884) ~[?:1.8.0_121]
	at java.lang.SecurityManager.checkPermission(SecurityManager.java:549) ~[?:1.8.0_121]
	at java.lang.SecurityManager.checkSecurityAccess(SecurityManager.java:1759) ~[?:1.8.0_121]
	at java.security.Provider.check(Provider.java:658) ~[?:1.8.0_121]
	at java.security.Provider.put(Provider.java:317) ~[?:1.8.0_121]
	at org.apache.hadoop.security.SaslPlainServer$SecurityProvider.<init>(SaslPlainServer.java:41) ~[?:?]
	at org.apache.hadoop.security.SaslRpcServer.init(SaslRpcServer.java:181) ~[?:?]
	at org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:581) ~[?:?]
	at org.apache.hadoop.hdfs.NameNodeProxiesClient.createNonHAProxyWithClientProtocol(NameNodeProxiesClient.java:343) ~[?:?]
	at org.apache.hadoop.hdfs.NameNodeProxies.createNonHAProxy(NameNodeProxies.java:170) ~[?:?]
	at org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider$DefaultProxyFactory.createProxy(ConfiguredFailoverProxyProvider.java:67) ~[?:?]
	at org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.getProxy(ConfiguredFailoverProxyProvider.java:151) ~[?:?]
	at org.apache.hadoop.io.retry.RetryInvocationHandler$ProxyDescriptor.failover(RetryInvocationHandler.java:221) ~[?:?]
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processRetryInfo(RetryInvocationHandler.java:147) ~[?:?]
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.processWaitTimeAndRetryInfo(RetryInvocationHandler.java:140) ~[?:?]
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:107) ~[?:?]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:335) ~[?:?]
	at com.sun.proxy.$Proxy34.mkdirs(Unknown Source) ~[?:?]
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2525) ~[?:?]
	at org.apache.hadoop.fs.Hdfs.mkdir(Hdfs.java:311) ~[?:?]
	at org.apache.hadoop.fs.FileContext$4.next(FileContext.java:738) ~[?:?]
	at org.apache.hadoop.fs.FileContext$4.next(FileContext.java:734) ~[?:?]
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90) ~[?:?]
	at org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:741) ~[?:?]
	at org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:65) ~[?:?]
	at org.elasticsearch.repositories.hdfs.HdfsBlobStore$2.run(HdfsBlobStore.java:62) ~[?:?]
	at org.elasticsearch.repositories.hdfs.HdfsBlobStore.lambda$execute$0(HdfsBlobStore.java:132) ~[?:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_121]
	at java.security.AccessController.doPrivileged(AccessController.java:713) ~[?:1.8.0_121]
	at org.elasticsearch.repositories.hdfs.HdfsBlobStore.execute(HdfsBlobStore.java:129) ~[?:?]
	at org.elasticsearch.repositories.hdfs.HdfsBlobStore.mkdirs(HdfsBlobStore.java:62) ~[?:?]
	at org.elasticsearch.repositories.hdfs.HdfsBlobStore.<init>(HdfsBlobStore.java:55) ~[?:?]
	at org.elasticsearch.repositories.hdfs.HdfsRepository.doStart(HdfsRepository.java:116) ~[?:?]
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.repositories.RepositoriesService.createRepository(RepositoriesService.java:384) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.repositories.RepositoriesService.applyClusterState(RepositoriesService.java:303) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.2.jar:5.6.2]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]

